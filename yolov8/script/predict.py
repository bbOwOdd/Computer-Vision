"""
YOLOv8 æ¨è«–/æ¸¬è©¦è…³æœ¬
ä½¿ç”¨æ–¹æ³•: python .\scripts\predict.py --model results\train\weights\best.pt --source datasets\vehicle\TrafficPolice.mp4 --save --show --save-txt --save-conf
"""

import argparse
import os
from pathlib import Path
from ultralytics import YOLO
import cv2
import torch

def parse_args():
    """è§£æå‘½ä»¤è¡Œåƒæ•¸"""
    parser = argparse.ArgumentParser(description='YOLOv8 Prediction Script')
    parser.add_argument('--model', type=str, required=True,
                       help='è¨“ç·´å¥½çš„æ¨¡å‹è·¯å¾‘ (.pt æª”æ¡ˆ)')
    parser.add_argument('--source', type=str, required=True,
                       help='è¼¸å…¥ä¾†æº (åœ–ç‰‡è·¯å¾‘ã€è³‡æ–™å¤¾ã€å½±ç‰‡æˆ–æ”å½±æ©Ÿ)')
    parser.add_argument('--conf', type=float, default=0.25,
                       help='ä¿¡å¿ƒåº¦é–¾å€¼')
    parser.add_argument('--iou', type=float, default=0.7,
                       help='NMS IoU é–¾å€¼')
    parser.add_argument('--project', type=str, default='results',
                       help='çµæœå„²å­˜å°ˆæ¡ˆåç¨±')
    parser.add_argument('--name', type=str, default='predict',
                       help='å¯¦é©—åç¨±')
    parser.add_argument('--device', type=str, default='cpu',
                       help='CUDA device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--save', action='store_true',
                       help='å„²å­˜é æ¸¬çµæœ')
    parser.add_argument('--show', action='store_true',
                       help='é¡¯ç¤ºé æ¸¬çµæœ')
    parser.add_argument('--save-txt', action='store_true',
                       help='å„²å­˜çµæœç‚º txt æ ¼å¼')
    parser.add_argument('--save-conf', action='store_true',
                       help='åœ¨æ¨™ç±¤ä¸­å„²å­˜ä¿¡å¿ƒåº¦')   
    
    return parser.parse_args()

def main():
    """ä¸»å‡½æ•¸"""
    args = parse_args()
    
    print("ğŸ”® é–‹å§‹ YOLOv8 æ¨è«–")
    print(f"ğŸ§  æ¨¡å‹: {args.model}")
    print(f"ğŸ“ ä¾†æº: {args.source}")
    print(f"ğŸ¯ ä¿¡å¿ƒåº¦é–¾å€¼: {args.conf}")
    print(f"ğŸ“Š IoU é–¾å€¼: {args.iou}")
    
    # æª¢æŸ¥ GPU å¯ç”¨æ€§
    if torch.cuda.is_available():
        print(f"ğŸ® ä½¿ç”¨ GPU: {torch.cuda.get_device_name()}")
        if not args.device:
            args.device = 0
    else:
        print("ğŸ’» ä½¿ç”¨ CPU æ¨è«–")
        args.device = 'cpu'
    
    # æª¢æŸ¥æ¨¡å‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.model):
        print(f"âŒ æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨: {args.model}")
        return
    
    # æª¢æŸ¥ä¾†æºæ˜¯å¦å­˜åœ¨
    if not os.path.exists(args.source):
        print(f"âŒ ä¾†æºä¸å­˜åœ¨: {args.source}")
        return
    
    # è¼‰å…¥æ¨¡å‹
    try:
        model = YOLO(args.model)
        print(f"âœ… æˆåŠŸè¼‰å…¥æ¨¡å‹: {args.model}")
    except Exception as e:
        print(f"âŒ è¼‰å…¥æ¨¡å‹å¤±æ•—: {e}")
        return
    
    # åŸ·è¡Œæ¨è«–
    try:
        results = model.predict(
            source=args.source,
            conf=args.conf,
            iou=args.iou,
            save=args.save,
            show=args.show,
            save_txt=args.save_txt,
            save_conf=args.save_conf,
            project=args.project,
            name=args.name,
            device=args.device,
            verbose=True,
        )
        
        print("ğŸ‰ æ¨è«–å®Œæˆï¼")
        if args.save:
            print(f"ğŸ“ çµæœå„²å­˜åœ¨: {args.project}")
        
        # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
        total_detections = 0
        for result in results:
            if result.boxes is not None:
                total_detections += len(result.boxes)
        
        print(f"ğŸ” ç¸½å…±æª¢æ¸¬åˆ° {total_detections} å€‹ç‰©ä»¶")
        
    except Exception as e:
        print(f"âŒ æ¨è«–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        return

if __name__ == '__main__':
    main()
